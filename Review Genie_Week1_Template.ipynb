{"cells":[{"cell_type":"markdown","source":["# Review Genie - A conversation Chatbot for an E-Commerce Application"],"metadata":{"id":"CkaZ15bkt6SM"}},{"cell_type":"markdown","metadata":{"id":"5TYwjqpUdeS5"},"source":["# Overview of Week 1\n","\n","Key Objectives - In the first week of Review Genie, our goals are as follows:\n","\n","- Understanding the overall business problem\n","- Identifying the key milestones that we have to close\n","- Understand the apply the key tools that we need here\n","- Building a simple POC app, that will set the groundwork for the subsequent weeks.\n","\n","\n","\n","**Structure of this Notebook**\n","\n","- Basics of RAG.\n","  - The Need for RAG\n","  - Basic RAG app architecture\n","  - Tools for building the RAG app\n","- Building ReviewGenie POC\n","  - Data Preparation\n","  - Vector Store Setup\n","  - Building the chatbot\n","  - Building a simple Gradio UI\n"]},{"cell_type":"markdown","metadata":{"id":"NS3n2y8wPw5g"},"source":["## Basics of RAG\n","\n","Before we start coding, lets go over a few questions and get it clarified.\n","\n","### 1. What is RAG?\n","Imagine you're writing an article about climate change, but instead of relying only on what you remember, you search online for recent studies and data to support your writing. RAG works the same way—it combines a powerful LLMs with a search system that retrieves relevant information from an external knowledge source, like a database or documents. This helps generate more accurate and informative responses.\n","\n","### 2. Why is RAG important?\n","RAG is crucial because LLM models, like ChatGPT, can sometimes \"hallucinate\" or provide outdated or incorrect information. By retrieving facts from trusted sources before generating responses, RAG ensures the answers are more reliable, up-to-date, and contextually relevant.\n","\n","### 3. What’s the difference between RAG and a standard LLM chatbot?\n","A standard chatbot relies only on pre-trained knowledge, which may be limited or outdated. RAG-enhanced chatbots, however, actively retrieve fresh, relevant information from external sources, ensuring better accuracy and up-to-date insights.\n","\n","### 4. What are the key components of RAG?\n","RAG consists of two main parts:\n","\n","- Retriever: Finds the most relevant documents or data from a knowledge base (e.g., a search engine or database).\n","- Generator: Uses the retrieved information to produce a coherent and accurate response.\n","\n","### 5. Usecases in real-life\n","- Customer Support: LLM chatbots retrieve knowledge base articles to provide better responses to customer queries.\n","- Healthcare: Doctors can get AI-assisted summaries of patient records and the latest medical research.\n","- Legal Services: Lawyers can search through legal documents and case studies to build stronger cases."]},{"cell_type":"markdown","metadata":{"id":"R-9ZmExzDRva"},"source":["### Understanding the Limitation of the LLM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRit5A9KCx20"},"outputs":[],"source":["# Importing the OpenAI library to interact with OpenAI's API services.\n","from openai import OpenAI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKBjz45zDj6r","outputId":"d345656f-92e2-4b36-dbdc-20dd9d13275a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your OpenAI API key: ··········\n"]}],"source":["import os  # Importing the os module to interact with environment variables\n","import getpass  # Importing getpass to securely input sensitive information\n","\n","# Prompting the user to securely enter their OpenAI API key without displaying it on the screen\n","OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API key: \")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7YY7aEjDj9I"},"outputs":[],"source":["# Creating an instance of the OpenAI client using the provided API key.\n","client = OpenAI(api_key=              )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtvWPnanDkAj"},"outputs":[],"source":["# Defining the prompt to query the LLM\n","prompt = ''' What was uber's revenue in 2022? '''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBFCA_A_DWBp"},"outputs":[],"source":["# Sending a request to the OpenAI API to generate a chat response\n","openai_response = client.chat.completions.create(\n","    model='gpt-3.5-turbo',  # Specifying the model to use;\n","    # Note: An older model chosen for testing purposes because the cutoff is 2021 whereas prompt is querying details about 2022\n","    messages=[{'role': 'user', 'content': prompt}]  # Creating a structured message for the LLM model\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"WONjF1M1Xs-k"},"source":["In the above code, while creating a structured message for the LLM model,  `role `defines the speaker (user input) and `content` contains the actual query stored in the `prompt` variable.\n","\n","We are structuring the input this way because OpenAI's chat models require a specific format to understand and process conversations effectively. Assigning roles like 'user' helps the LLM distinguish between different participants in the conversation, ensuring it provides relevant and context-aware responses."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2u-Y1hWlDij2"},"outputs":[],"source":["# Accessing the generated response from the LLM.\n","\n","\n","\n","# Note:'choices' contains multiple response options, we take the first one ([0]),\n","# 'message' holds the response details, and 'content' extracts the actual text generated by the LLM."]},{"cell_type":"markdown","metadata":{"id":"EJLYV5B_YWGD"},"source":["### Interpretation:\n","Why is the LLM not able to answer the query?\n","\n","\n","\n","#### Do it yourself:\n","Try changing the model to `gpt-4o-mini` and observe how the output changes!"]},{"cell_type":"markdown","metadata":{"id":"QXHhy-hcEMyy"},"source":["### Making the LLM context-aware\n","\n","Next Step: Let's check Uber's [financial report ](https://s23.q4cdn.com/407969754/files/doc_events/2024/May/06/2023-annual-report.pdf)\n","\n","On Page 54, of the above document it states:\n","\n","\"Revenue was 37.3 billion, up 17% year-over-year. Mobility revenue increased 5.8 billion primarily attributable to an increase in\n","Mobility Gross Bookings of......\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSAk_2EGD1CC"},"outputs":[],"source":["## Let's create the above context for the prompt\n","# Defining a context string with revenue details retrieved from an external source.\n","retrieved_context = '''Revenue was $37.3 billion, up 17% year-over-year. Mobility revenue increased $5.8 billion primarily attributable to an increase in\n","               Mobility Gross Bookings of 31% year-over-year.'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Irw2unBKFb0M"},"outputs":[],"source":["## Let's modify our prompt now\n","# Creating a prompt by embedding the retrieved context into a question for the LLM.\n","\n","prompt = f\"What was Uber's revenue in 2022? Check in {         }\"\n","\n","# Note: The LLM is being asked to analyze the given context and provide Uber's revenue for 2022"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R70ZN0eKFoo7"},"outputs":[],"source":["## Let's ask the LLM again\n","openai_response = client.chat.completions.create(\n","    model = 'gpt-3.5-turbo',\n","    messages =                           )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09ddo9F1Fs-w"},"outputs":[],"source":["# Accessing the generated response from the LLM model.\n","openai_response.choices[0].message.content"]},{"cell_type":"markdown","metadata":{"id":"6LuE9mCnbR7u"},"source":["### Interpretation:\n","How is the LLM able to answer the same question now?\n","\n","The LLM can now answer the question accurately because the relevant financial data is explicitly provided in the `retrieved_context`, allowing the model to reference it directly instead of relying on its pre-trained knowledge."]},{"cell_type":"markdown","metadata":{"id":"nfpLPTtDG57l"},"source":["As you saw in the example above, we\n","\n","- **retrieved** the context from an external source\n","- **augmented** our prompt that passes to the LLM, and\n","- **generated** the response\n","\n","This is Retrieval Augmented Generation in a nutshell!"]},{"cell_type":"markdown","metadata":{"id":"uKzjA8hmHtaA"},"source":["### Basic RAG app architecture\n","\n","In the previous example, we manually retrieved the context from the given file which for all purposes is impractical (duh!!)\n","\n","Therefore, we have to devise a strategy that enables us to:\n","\n","- Take the query from the user\n","- Identify the documents from the external source that might be relevant for the query.\n","- Pass those documents' information as context to the LLM\n","- LLM then generates the final response"]},{"cell_type":"markdown","metadata":{"id":"msqpnuzuJHYY"},"source":["To do the above, we can follow a simple standard architecture as shown below (Image source - https://huyenchip.com/2024/07/25/genai-platform.html)\n","\n","<center><img src=\"https://huyenchip.com/assets/pics/genai-platform/3-rag.png\" width=500 height=400/></center>"]},{"cell_type":"markdown","metadata":{"id":"JXm08cxzLsia"},"source":["As you can see in the above image, the retriever would be the key component of this entire architecture.\n","\n","To build the retriever, we have to follow these steps:\n","\n","- Connect to the document source\n","- Break the documents down to manageable chunks. This is due to the fact that taking in the entire document source for building the context will exceed the token limits of the LLM. This process is also called **Chunking**.\n","- Perform a search for the most relevant chunks based on the given query.\n","- Pass those relevant chunks to the LLM.\n","\n","For performing the search or retrieval process, we will be following an **embedding-based approach.**\n","\n","<center><img src=\"https://cdn.prod.website-files.com/640248e1fd70b63c09bd3d09/653fd23f1565c0c1da063efc_Semantic%20Search%20Text%20Embeddings%20(1).png\" width =500/></center>"]},{"cell_type":"markdown","metadata":{"id":"6MPW_40jNLDn"},"source":["### Understanding Embedding based approach\n","\n","In the embedding based approach:\n","\n","- We convert the document chunks in the database to vector embeddings and store it in a vector store.\n","\n","- Convert the given user query to an embedding.\n","\n","- Find the document chunks whose vector embeddings are closest to the given query embedding using a vector search algorithm like FAISS (Facebook AI Similarity Search)\n","\n","<center><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*h_btyitJX79d-gFE8RaMQg.png\" width=500/></center>"]},{"cell_type":"markdown","metadata":{"id":"K7aMQOXtON5U"},"source":["### Tools for building the RAG App\n","\n","Now that we are familiar with the overall architecture, we can now go ahead and structure the tools that we'll use for the upcoming demonstration:\n","\n","- OpenAI LLM (model - GPT 4o-mini): This will be our primary model for generating the responses\n","- LangChain: Langchain is a powerful framework for orchestrating different layers in the RAG app. We shall use this to build the retriever end-to-end and also connect with other tools for tasks such as\n","    - Chunking - RecursiveCharacterTextSplitter\n","    - Embedding Model - OpenAIEmbeddings\n","    - Vector Search Model - FAISS\n","- Gradio: This will help in building a simple UI at the end."]},{"cell_type":"markdown","metadata":{"id":"ey558a81QcXs"},"source":["## Building ReviewGenie POC\n","\n","*A basic chatbot that can answer customer queries*\n","\n","## Problem Statement\n","Shopping online can be overwhelming. You search for a simple pair of shoes, but end up scrolling through countless options—many irrelevant, some too expensive, others just not right. Traditional search engines rely on keywords, often missing what you truly need.\n","\n","Let's build an AI-powered product discovery chatbot changes this. Using advanced language models and vector-based search, it goes beyond keywords to understand your intent, offering personalized, context-aware recommendations in seconds.\n","\n","<center><img src=\"https://www.pranathiss.com/static/assets/images/ai-powered-chatBot.webp\" width=500/></center>\n","\n","This smart solution enhances the shopping experience, increasing customer satisfaction, engagement, and conversions. The future of e-commerce is here—smarter, intuitive, and built for you.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HQfzsw36du3S"},"source":["### Dataset Used:\n","The given dataset contains information about various products, including their IDs, descriptions, and specifications. Below is a detailed description of each column and the type of data it contains.\n","\n","You can download the entire dataset [here](https://www.kaggle.com/datasets/piyushjain16/amazon-product-data).\n","Or you can download the smaller sample dataset [here](https://drive.google.com/file/d/1ohd9xo19HmDVIwpXPf_IyMkwr29gJJxR/view?usp=drive_link).\n","\n","#### Column Descriptions:\n","- `PRODUCT_ID (Integer)`\n","A unique identifier assigned to each product.\n","Example: 1925202, 2673191\n","- `TITLE (String)`\n","The name or title of the product, usually a brief summary.\n","Example: \"ArtzFolio Tulip Flowers Blackout Curtain for D...\",\n","\"Marks & Spencer Girls' Pyjama Sets T86_2561C_N...\"\n","- `BULLET_POINTS (List of Strings / NaN)`\n","A list of key product features and benefits in bullet format.\n","- `DESCRIPTION (String / NaN)`\n","A detailed textual description of the product, including specifications, features, and usage instructions.\n","Example: \"Specifications: Color: Red, Material: Aluminium...\"\n","- `PRODUCT_TYPE_ID (Integer / NaN)`\n","A numeric identifier indicating the type or category of the product.\n","Example: 1650, 2996, 7537\n","- `PRODUCT_LENGTH (Float)`\n","The length of the product, likely measured in millimeters or inches.\n","Example: 2125.98, 393.7, 748.031495"]},{"cell_type":"markdown","metadata":{"id":"d2OGXS6YSl5Y"},"source":["### Steps:\n","\n","1. **Data Preparation**:\n","   - Load and process the dataset using pandas\n","\n","2. **Vector Store Setup**:\n","   - Convert product descriptions into embeddings.\n","   - Store embeddings in a vector database.\n","\n","3. **Building the Chatbot**:\n","   - Use LangChain to create an LLM pipeline.\n","   - Develop a simple chatbot to answer product-related queries.\n","\n","4. **Creating a UI**:\n","   - Implement a Gradio-based UI for user interaction."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ekric37zU6aV","outputId":"8f94020f-cf09-472d-9bf9-2a710dcbd9a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchainhub in /usr/local/lib/python3.11/dist-packages (0.1.21)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (2.32.3)\n","Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (2.32.0.20241016)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (2024.12.14)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.1)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.30 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.31)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.59.6)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.8.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (1.33)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (0.2.10)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (24.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (2.10.5)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (9.0.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.30->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.30->langchain-openai) (3.10.14)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.30->langchain-openai) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.30->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.30->langchain-openai) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.15)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.14)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain) (3.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.15)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.2.10)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (0.3.5)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (2.10.5)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.14)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (2.27.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.15)\n","Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.5.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.2.10)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n","Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.8.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (0.3.5)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (2.10.5)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (4.12.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.14)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (2.27.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.13.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.7)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n","Requirement already satisfied: gradio-client==1.6.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.6.0)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.2)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.2)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n","Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"]}],"source":["# Installing the LangChain Hub package to access and manage pre-built AI chains, prompts, and agents.\n","!pip install langchainhub\n","\n","# Installing the LangChain OpenAI integration to use OpenAI models within LangChain workflows.\n","!pip install langchain-openai\n","\n","# Installing the core LangChain library for building LLM-based applications, including chaining, memory, and retrieval capabilities.\n","!pip install langchain\n","\n","# Installing the community version of LangChain, which includes integrations and tools contributed by the community.\n","!pip install langchain-community\n","\n","# Installing FAISS (Facebook AI Similarity Search) for efficient similarity-based search on text embeddings.\n","!pip install faiss-cpu\n","\n","# Installing Gradio, a framework to create web-based UIs for AI models and applications easily.\n","!pip install gradio\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KqC1rIL7IyXt"},"outputs":[],"source":["# Importing the KaggleHub library to interact with datasets and models available on Kaggle.\n","import kagglehub\n","\n","# Importing the CSV module for reading and writing CSV files.\n","import csv\n","\n","# Importing pandas for data manipulation and analysis.\n","import pandas as pd\n","\n","# Importing numpy for numerical operations and handling arrays efficiently.\n","import numpy as np\n","\n","# Importing os to interact with the operating system, such as environment variables and file paths.\n","import os\n","\n","# Importing getpass to securely handle user input (e.g., API keys or passwords).\n","import getpass\n"]},{"cell_type":"markdown","metadata":{"id":"V9Vphy17StbK"},"source":["### STEP 1: Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sh9WpGhWRpCU","outputId":"8903fdf9-6ce0-4cea-bc1e-81dd8972571f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XiPvpp1FxKb"},"outputs":[],"source":["# Loading the data\n","df = pd.read_csv(                             ,index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MznuqvAmRx_g"},"outputs":[],"source":["# Viewing the data\n"]},{"cell_type":"markdown","metadata":{"id":"y-3RpjmUS21M"},"source":["**Constructing the text data**\n","\n","It's useful to use both `Title` and `Description`. To help downstream models understand which content is title and which content is description, we will add a prefix explaining which section is title and which is description. So each row should look like\n","\n","```\n","Title\n","{Title}\n","Description\n","{Description}\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MduzbFnMSdNo"},"outputs":[],"source":["## Let's construct the text data\n","# Initializing empty lists to store product descriptions and their lengths\n","product_description =\n","product_description_len =\n","\n","# Iterating through each row in the dataframe df2\n","for row in df2.iterrows():\n","    product = \"\"  # Initialize an empty string to accumulate product details\n","\n","    # Extracting the product title from the current row\n","    title =\n","\n","    # Checking if the title is valid (not NaN or missing)\n","    if type(title) != float or not math.isnan(title):\n","        product += \"Title\\n\" + title + \"\\n\"  # Append the title to the product description\n","\n","    # Extracting the product description from the current row\n","    description =\n","\n","    # Checking if the description is valid (not NaN or missing)\n","    if type(description) != float or not math.isnan(description):\n","        product += \"Description\\n\" + description + \"\\n\"  # Append the description to the product details\n","\n","    # Check if either title or description was added\n","    added_content = title or description\n","    if added_content:\n","        product = product.strip()  # Remove any leading/trailing whitespace\n","        product_description.append(product)  # Add the formatted product details to the list\n","        product_description_len.append(len(product))  # Store the length of the product description\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rd2Tpb2dTeQc"},"outputs":[],"source":["# Checking the length of the data\n","print(f\"Number of elements {len(product_description)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7JLY31mTx0l"},"outputs":[],"source":["# Check a sample product description data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kaPPz4ebT0P4"},"outputs":[],"source":["# Print the total number of product descriptions processed\n","print(\"Number of items\", len(product_description_len))\n","\n","# Print the minimum length of the product descriptions\n","print(\"Min Length of the description:\",np.min(product_description_len))\n","\n","# Print the average (mean) length of the product descriptions\n","print(\"Avg Length of the description:\",np.mean(product_description_len))\n","\n","# Print the maximum length of the product descriptions\n","print(\"Max Length of the description:\",np.max(product_description_len))"]},{"cell_type":"markdown","metadata":{"id":"R4y4JSH_Svat"},"source":["### Interpretation:\n","\n","What does the above result signify about the data?\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xRjed6aXUo6j"},"source":["### STEP 2: Vector Store Setup\n","\n","Let's try to get a few of the basic questions answered about vector stores before we start using it.\n","\n","### What is a vector store?\n","A vector store is a specialized database that stores data in the form of numerical vectors, allowing efficient searching and retrieval based on similarity rather than exact matches.\n","\n","### Why do we need a vector store?\n","Traditional databases rely on exact keyword matches, which can miss relevant information. A vector store helps find similar content by understanding relationships and meaning in data.\n","\n","### How does a vector store work?\n","It converts text, images, or other data into numerical vectors using ML\n"," models, then stores these vectors and retrieves similar ones using techniques like cosine similarity.\n","\n","### How does a vector store improve search results?\n","It enables searches based on meaning rather than just keywords, providing more relevant results even if the exact terms don't match.\n","\n","### What are some popular vector store tools?\n","- FAISS (Facebook AI Similarity Search)\n","- Pinecone\n","- Weaviate\n","- Chroma\n","\n","### What is an embedding, and how does it relate to a vector store?\n","An embedding is a numerical representation of data (e.g., text, image) that captures its meaning. These embeddings are stored in a vector store for efficient retrieval.\n","\n","\n","Our next step is\n","-  to convert the `product_description` to chunks\n","-  convert each chunk to embedding\n","-  store it in vector store for searching\n","\n","As discussed earlier we shall use `LangChain` to perform these steps.\n","\n","LangChain is a framework that helps developers build applications powered by large language models (LLMs) like GPT by providing tools for various tasks to be carried out like retrieving relevant information from databases, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hwFdqweOT2xI"},"outputs":[],"source":["# Importing RecursiveCharacterTextSplitter from LangChain for chunking large text into smaller, manageable pieces.\n","# This helps in optimizing text for processing and retrieval.\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","# Importing OpenAIEmbeddings from LangChain to generate numerical vector representations (embeddings) of text.\n","# These embeddings capture the semantic meaning of the text for efficient similarity searches.\n","from langchain_openai import OpenAIEmbeddings\n","\n","# Importing FAISS (Facebook AI Similarity Search) from LangChain's community package.\n","# FAISS is used for storing and retrieving embeddings efficiently by finding similar vectors.\n","from langchain_community.vectorstores import FAISS\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2X3hxmTTUsr1"},"outputs":[],"source":["# Setting the OpenAI API key as an environment variable.\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PD-uoBzLVtdw"},"outputs":[],"source":["# Split the input text using Recursive Character Chunking\n","# See this for more details https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/\n","\n","text_splitter =\n","documents ="]},{"cell_type":"markdown","source":["### Code Explanation:\n","The above code initializes a `RecursiveCharacterTextSplitter` to break down product_description into smaller text chunks of 250 characters each, with a 20-character overlap to preserve context between chunks. The `create_documents` function processes the text list and generates structured document chunks for efficient retrieval and analysis.\n","\n","### Why do we need overlap?\n","Overlap is needed to ensure continuity and preserve context between chunks, preventing important information from being cut off at chunk boundaries. This helps LLMs better understand the text when processing each chunk independently, improving retrieval accuracy and response quality."],"metadata":{"id":"MqtfA0tXh7CL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptE8XpNLWD--"},"outputs":[],"source":["# Create an embedding model using LangChain.\n","# One option is using https://python.langchain.com/docs/integrations/text_embedding/openai/\n","# See https://python.langchain.com/docs/integrations/text_embedding/ for a list of available embedding models on LangChain\n","embeddings ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSlO9vblWGDt"},"outputs":[],"source":["# Create a vector store using the created chunks and the embeddings model\n","vector ="]},{"cell_type":"markdown","source":["### What have we done so far?\n","1. Data Preparation: Extracted the product description data\n","2. Data Chunking: Converted the entire data into multiple manageable chunks\n","3. Chunks to Embeddings: Converted the broken down chunks into embeddings\n","4. Storage in a Vector DB: Stored the resulting embeddings of chunks in a vector store for effective retrieval.\n","\n","\n","### What is remaining?\n","- Building the chatbot\n","- Building the Gradio UI"],"metadata":{"id":"nNhCKF9Nig_n"}},{"cell_type":"markdown","metadata":{"id":"c24S9JsfWSa7"},"source":["### STEP 3: Building the chatbot\n","\n","Now that we have converted the documents to embeddings, our next step is to\n","- build a retriever that uses the vector store to retrieve the documents\n","- create a prompt template that contains the augmented context using the retrieved documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nElsMdbeW4l1"},"outputs":[],"source":["# Importing ChatOpenAI from LangChain to interact with OpenAI's language models, such as GPT, for generating responses.\n","from langchain_openai import ChatOpenAI\n","\n","# Importing ChatPromptTemplate to create structured prompts for the chatbot, ensuring consistent interactions with the LLM model.\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","# Importing OpenAIEmbeddings to convert text data into numerical vector representations for similarity search and retrieval.\n","from langchain_openai import OpenAIEmbeddings\n","\n","# Importing ChatPromptTemplate again (duplicate import, should be removed to avoid redundancy).\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","# Importing create_stuff_documents_chain to combine and process retrieved documents for meaningful AI-generated responses.\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","\n","# Importing create_retrieval_chain to build a chain that retrieves relevant documents from a vector store and generates AI responses.\n","from langchain.chains import create_retrieval_chain\n","\n","# Importing StrOutputParser from LangChain to parse the output\n","from langchain_core.output_parsers import StrOutputParser"]},{"cell_type":"markdown","source":["#### Code Explanation:\n","- `ChatOpenAI` – Used to access OpenAI models for chatbot functionality.\n","- `ChatPromptTemplate` – Helps structure queries to ensure better responses.\n","- `OpenAIEmbeddings` – Converts text into vector form for similarity-based retrieval.\n","- `create_stuff_documents_chain` – Combines retrieved documents meaningfully before passing to the LLM.\n","- `create_retrieval_chain` – Automates the process of retrieving and utilizing relevant content for AI responses.\n","- `StrOutputParser` - For processing the output of language models, ensuring that the output is returned as a plain string"],"metadata":{"id":"xVChvJAijx-1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dJXzILCXStu"},"outputs":[],"source":["# Initializing the ChatOpenAI model to interact with OpenAI's GPT model.\n","llm = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model = 'gpt-4o-mini')"]},{"cell_type":"code","source":["# Importing the output parser to process and format the model's response into a readable string format.\n","output_parser =\n","\n","# Creating a prompt template that instructs the LLM to act as a customer service agent.\n","# The prompt takes two parameters:\n","#   1. {context} - Relevant information retrieved from the document store.\n","#   2. {input} - The user's question.\n","# The model is instructed to base its answer solely on the provided context.\n","prompt = ChatPromptTemplate.from_template(\n","    \"\"\"Answer the following question based only on the provided context:\n","\n","    <context>\n","    {context}\n","    </context>\n","\n","    Question: {input}\"\"\",\n","    output_parser=                  # The output parser ensures that the response is returned in a structured string format.\n",")\n","\n","# Creating a document processing chain using the LLM and the defined prompt\n","# template.\n","# This chain takes a list of retrieved documents and passes them as context to\n","# the model for generating responses.\n","document_chain =\n","\n","# Alternative chain creation method:\n","# Using the \"|\" (pipe) operator to link the prompt with the language model (llm),\n","# meaning the input first goes to the prompt and then to the model for\n","# response generation.\n","# document_chain = prompt | llm\n"],"metadata":{"id":"dPJ3yFeEk9EN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Code Explanation:\n","- A structured prompt is created using `ChatPromptTemplate` to guide LLMs in answering questions based solely on provided context.\n","- The prompt includes placeholders `{context}` and `{input}` to dynamically inject relevant information.\n","- `StrOutputParser()` ensures that the LLM's response is formatted as plain text for easy processing and display.\n","- `create_stuff_documents_chain(llm, prompt)` combines the language model (LLM) with the prompt to form a processing chain. This chain takes retrieved documents as input and generates AI-driven responses.\n","- Alternate way:  `prompt | llm` is a more concise way to chain the prompt and model, achieving the same functionality with a cleaner syntax."],"metadata":{"id":"__HKSf_Umiq4"}},{"cell_type":"code","source":["# Create a retriever from the vector store for fetching relevant documents\n","# See https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/vectorstore/\n","retriever =\n","\n","# Create a retrieval chain that first retrieves relevant documents and then processes them using the document chain\n","retrieval_chain =\n"],"metadata":{"id":"VMiWghjrl5oB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Code Explanation:\n","- The `vector.as_retriever()` converts the vector store into a retriever to find documents based on query similarity.\n","- The `create_retrieval_chain()` connects the retriever with the document processing pipeline, ensuring LLM receives relevant context before generating responses.\n","\n","This setup enables LLM to provide accurate answers by first retrieving and then processing relevant documents."],"metadata":{"id":"xY3X-YJZmT3T"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUqxhEW3XcJX"},"outputs":[],"source":["# Invoking the retrieval chain to process the user's query.\n","# The query \"what are some of the best shoes available?\" is passed as input.\n","# The retrieval chain first fetches relevant product descriptions from the vector store,\n","# then processes them using the document chain to generate a meaningful LLM response.\n","retrieval_chain.invoke({\"input\": \"what are some of the best shoes available?\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QqNvod6GXfjx"},"outputs":[],"source":["# Fetching the final answer from the retrieval chain by invoking it with a user query.\n","# The ['answer'] key extracts the final LLM-generated answer from the response dictionary.\n","retrieval_chain.invoke({\"input\": \"what are some of the best shoes available?\"})['answer']"]},{"cell_type":"markdown","source":["Now, we got the answer! But, the formatting is not very good, right? Lets create a simple UI for our bot."],"metadata":{"id":"2tMQ3SGUnoad"}},{"cell_type":"markdown","metadata":{"id":"QvDsSk-bYSwS"},"source":["### STEP 4: Building a simple Gradio UI\n","\n","Gradio is an open-source Python library that makes it easy to build interactive user interfaces for machine learning models, APIs, and data science workflows. It allows developers to create shareable web-based UIs with just a few lines of code.\n","\n","To build the gradio app we'll utilize the following steps:\n","\n","- Modularize the entire RAG pipeline using a single function\n","- Create the building blocks for the UI.\n","- Connect the UI with the function"]},{"cell_type":"code","source":["# Function to process the user query and return formatted product names\n","def final_response(user_query):\n","    # Invoking the retrieval chain with the user's query to fetch relevant product information\n","    response = retrieval_chain.invoke({\"input\": user_query})['answer']\n","\n","    # Creating a prompt to instruct the LLM to format the response properly\n","    # The prompt asks the LLM to extract only product names from the retrieved response\n","    prompt = f\"Format the responses properly in {response}. Just return the product names, no other text\"\n","\n","    # Sending the formatted prompt to the GPT-4o-mini model for processing\n","    openai_response = client.chat.completions.create(\n","        model='gpt-4o-mini',  # Using GPT-4o-mini model for response generation\n","        messages=[{'role': 'user', 'content': prompt}]  # Providing the prompt to the model\n","    )\n","\n","    # Extracting and returning the LLM-generated response containing only the product names\n","    return openai_response.choices[0].message.content\n"],"metadata":{"id":"PcAbbKmKoHZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttosPCA2bLYz"},"outputs":[],"source":["# Printing the final response\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjS_RUh6ZstZ"},"outputs":[],"source":["# Importing the Gradio library to create a simple web-based user interface\n","import gradio as gr\n","\n","# Creating the Gradio interface for the product recommendation system\n","app = gr.Interface(\n","    fn=            ,        # The function that processes user input and returns recommendations\n","    inputs=           ,            # Input component: a text box for users to enter their query\n","    outputs=        ,           # Output component: a text box to display the LLM-generated response\n","    title=          ,     # The title of the web interface\n","    description=           ,# A brief description displayed to users\n","    theme=\"Ocean\",\n","    allow_flagging=\"never\"    # Disabling the flagging feature to remove the \"Flag\" button\n",")\n","\n","# Launching the Gradio app to start the interface and make it accessible via web browser\n","app.launch()\n"]},{"cell_type":"markdown","source":["### Next Steps for Experimentation\n","\n","In the above demonstration, we have created a very basic GUI-based RAG app. Before our next class, you are recommende to experiment the following\n","\n","- Try asking 10-15 questions and check the accuracy of the response.\n","- What would be a strategy that you might follow to evaluate the app's overall responses?\n","- Ask a few out-of-the-box questions (like \"What is the weather today in Seattle?\")\n","- Try asking the same question multiple times with a different wording\n","- In the same chat history, ask questions which are related to the response that was just provided.\n","- Use a different dataset (perhaps in a different format like pdf) and see how the architecture might change.\n","\n","<hr> <hr>"],"metadata":{"id":"5BG7LdhktfTq"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}